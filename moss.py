import numpy as np

EPS = 0.04

def transform_m(m):
    m = float(m)
    if m <= 0.9:
        return m
    t = (m - 0.9) / 0.1
    return 0.9 + t * (5 - 0.9)

# ======================================================================
# ðŸ’  MoSS_MVN â€” GeraÃ§Ã£o de scores no simplex via Normal Multivariada
# ======================================================================
def MoSS_MVN(
    n: int = 1000,
    n_classes: int = 3,
    alpha: np.ndarray | None = None,
    merging_factor: float | np.ndarray = 0.0,
):
    """
    Gera scores multiclasse sintÃ©ticos com base em uma 
    distribuiÃ§Ã£o Normal Multivariada (MVN) diagonal.

    ParÃ¢metros
    ----------
    n : int
        NÃºmero total de amostras.
    n_classes : int
        NÃºmero de classes.
    alpha : array-like, opcional
        ProporÃ§Ã£o de amostras por classe (soma deve ser 1).
        Caso None, usa distribuiÃ§Ã£o uniforme.
    merging_factor : float ou array-like
        Controla a variÃ¢ncia intra-classe:
          - float â†’ variÃ¢ncia uniforme para todas as classes
          - array â†’ variÃ¢ncia especÃ­fica por classe (tamanho = n_classes)

    Retorna
    -------
    X : np.ndarray
        Scores normalizados no simplex (n Ã— n_classes)
    y : np.ndarray
        RÃ³tulos de classe (n,)
    """
    merging_factor = np.clip(merging_factor, 0.0, 1.0)

    # DistribuiÃ§Ã£o de classes
    if alpha is None:
        alpha = np.ones(n_classes) / n_classes
    alpha = np.array(alpha)

    n_per_class = np.floor(n * alpha).astype(int)
    n_per_class[-1] = n - n_per_class[:-1].sum()

    # -----------------------------------------
    # 1) CentrÃ´ides fixos â€” vÃ©rtices do simplex
    # -----------------------------------------
    centers = np.eye(n_classes)

    # -----------------------------------------
    # 2) VariÃ¢ncia controlada por merging_factor
    # -----------------------------------------
    if isinstance(merging_factor, (int, float)):
        var_per_class = np.full(n_classes, float(merging_factor))
    else:
        var_per_class = np.array(merging_factor)

    covs = [
        np.diag(np.full(n_classes, transform_m(EPS + v)))
        for v in var_per_class
    ]

    # -----------------------------------------
    # 3) Amostragem das classes
    # -----------------------------------------
    X, y = [], []
    for c in range(n_classes):
        mean, cov = centers[c], covs[c]
        X_class = np.random.multivariate_normal(mean, cov, size=n_per_class[c])

        # Normaliza para o simplex
        X_class = np.abs(X_class)
        X_class /= X_class.sum(axis=1, keepdims=True)

        X.append(X_class)
        y.append(np.full(n_per_class[c], c))

    return np.vstack(X), np.concatenate(y)


# ======================================================================
# ðŸ”· MoSS_Dir â€” GeraÃ§Ã£o de scores via DistribuiÃ§Ã£o Dirichlet
# ======================================================================
def MoSS_Dir(
    n: int = 1000,
    n_classes: int = 3,
    alpha: np.ndarray | None = None,
    merging_factor: float | np.ndarray = 0.5,
):
    """
    Gera scores sintÃ©ticos multiclasse usando distribuiÃ§Ã£o Dirichlet.

    ParÃ¢metros
    ----------
    n : int
        NÃºmero total de amostras.
    n_classes : int
        NÃºmero de classes.
    alpha : array-like, opcional
        ProporÃ§Ã£o de amostras por classe (soma deve ser 1).
        Caso None, usa distribuiÃ§Ã£o uniforme.
    m : float ou array-like
        Controla a dispersÃ£o intra-classe:
          - m pequeno â†’ amostras concentradas no centrÃ³ide
          - m grande  â†’ amostras mais uniformes

    Retorna
    -------
    X : np.ndarray
        Scores dentro do simplex (n Ã— n_classes)
    y : np.ndarray
        RÃ³tulos de classe (n,)
    """
    merging_factor = np.clip(merging_factor, 0.1, 1.0)

    # DistribuiÃ§Ã£o de classes
    if alpha is None:
        alpha = np.ones(n_classes) / n_classes
    alpha = np.array(alpha)

    n_per_class = np.floor(n * alpha).astype(int)
    n_per_class[-1] = n - n_per_class[:-1].sum()

    # CentrÃ´ides fixos no simplex
    centers = np.eye(n_classes)

    X, y = [], []
    for c in range(n_classes):
        # m por classe (permite vetor)
        m_c = float(merging_factor[c]) if isinstance(merging_factor, (list, np.ndarray)) else float(merging_factor)
        m_c = np.clip(m_c, 0.0, 1.0)

        # Controle de concentraÃ§Ã£o
        high_conc = 10 if m_c < 0.5 else 3

        # Mistura entre centrÃ³ide puro e distribuiÃ§Ã£o uniforme
        center = centers[c]
        mean = center * (1 - m_c) + (m_c / n_classes)
        
                        # concentra mais                       # mais uniforme
        concentration = (1 - m_c) * (mean * high_conc) + m_c * np.ones(n_classes)

        # GeraÃ§Ã£o Dirichlet
        X_class = np.random.dirichlet(concentration, size=n_per_class[c])

        X.append(X_class)
        y.append(np.full(n_per_class[c], c))

    return np.vstack(X), np.concatenate(y)


# ======================================================================
# ðŸ”¶ MoSS â€” GeraÃ§Ã£o de amostras binÃ¡rias com controle de dispersÃ£
# =====================================================================

def MoSS(n=1000, alpha=0.5, merging_factor=0.5):
    """
    Gera amostras sintÃ©ticas binÃ¡rias com controle de dispersÃ£o via potÃªncia m.
    
    ParÃ¢metros
    ----------
    n : int
        NÃºmero total de amostras.
    alpha : float
        ProporÃ§Ã£o da classe positiva (classe 1).
    m : float
        Controle da concentraÃ§Ã£o/dispersÃ£o das amostras.
        m pequeno â†’ amostras mais prÃ³ximas a 0 ou 1;
        m grande â†’ amostras mais dispersas.
    
    Retorna
    -------
    X : np.ndarray, shape (n, 2)
        Amostras bidimensionais geradas.
    y : np.ndarray, shape (n,)
        Labels correspondentes (0 ou 1).
    """
    n_pos = int(n * alpha)
    n_neg = n - n_pos
    
    # Scores positivos
    p_score = np.random.uniform(size=n_pos) ** merging_factor
    # Scores negativos
    n_score = 1 - (np.random.uniform(size=n_neg) ** merging_factor)
    
    # ConstruÃ§Ã£o dos arrays de features (duas colunas iguais)
    X_pos = np.column_stack((p_score, p_score))
    X_neg = np.column_stack((n_score, n_score))
    
    # Labels correspondentes
    y_pos = np.ones(n_pos, dtype=int)
    y_neg = np.zeros(n_neg, dtype=int)
    
    # Concatenar dados positivos e negativos
    X = np.vstack((X_pos, X_neg))
    y = np.concatenate((y_pos, y_neg))
    
    return X, y
